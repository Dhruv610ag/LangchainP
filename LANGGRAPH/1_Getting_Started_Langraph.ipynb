{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Chatbots With Langgraph"
      ],
      "metadata": {
        "id": "qsFqqI3E8Xn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langgraph langsmith"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDGN7B1e8cX_",
        "outputId": "7caf3e87-cc3d-4658-e83f-27d54390a7bd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.6.6-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.12/dist-packages (0.4.16)\n",
            "Collecting langsmith\n",
            "  Downloading langsmith-0.4.23-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.74)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.6-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith) (3.11.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langsmith) (25.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith) (0.24.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith) (2.5.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
            "Downloading langgraph-0.6.6-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.4.23-py3-none-any.whl (378 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.8/378.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.6-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langsmith, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.4.16\n",
            "    Uninstalling langsmith-0.4.16:\n",
            "      Successfully uninstalled langsmith-0.4.16\n",
            "Successfully installed langgraph-0.6.6 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.6 langsmith-0.4.23 ormsgpack-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain_groq langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOSj_MR1AHBs",
        "outputId": "b4cb8371-9d93-4373-cb18-956193933014"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.3.7-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.74)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.23)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Collecting groq<1,>=0.30.0 (from langchain_groq)\n",
            "  Downloading groq-0.31.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
            "  Downloading langchain_core-0.3.75-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting requests<3,>=2 (from langchain)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain_groq) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain_groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq<1,>=0.30.0->langchain_groq) (4.15.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain_groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.30.0->langchain_groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_groq-0.3.7-py3-none-any.whl (16 kB)\n",
            "Downloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading groq-0.31.0-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.4/131.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.75-py3-none-any.whl (443 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.0/444.0 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, groq, dataclasses-json, langchain-core, langchain_groq, langchain_community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.74\n",
            "    Uninstalling langchain-core-0.3.74:\n",
            "      Successfully uninstalled langchain-core-0.3.74\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 groq-0.31.0 langchain-core-0.3.75 langchain_community-0.3.29 langchain_groq-0.3.7 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "groq_api_key=userdata.get('GROQ_API_KEY')\n",
        "langsmith=userdata.get('LANGCHAIN_API_KEY')\n"
      ],
      "metadata": {
        "id": "TgKIrwXJAjgA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = langsmith\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"]=\"CourseLanggraph\""
      ],
      "metadata": {
        "id": "YFpKBPoZBQAa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq"
      ],
      "metadata": {
        "id": "XJZl9uX-CFo7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"gemma2-9b-It\")\n",
        "llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9vOWf8yCJ4W",
        "outputId": "054822c6-103e-43fb-ec09-2479e1e360ce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7ee0a4b916a0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7ee0a4b91c40>, model_name='gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start Building Chatbot Using Langgraph"
      ],
      "metadata": {
        "id": "RDc7RviFCVKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph,START,END#shows the flow of the whole graph as well\n",
        "from langgraph.graph.message import add_messages#so the state graph needs to be changed every time so this function is used\n",
        "#when we will add query to the llm the llm will generate the reponse and that response will be added as the message and the state graph will keep on changing"
      ],
      "metadata": {
        "id": "bPcSBey6CUeF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):#inheriting the typeddict\n",
        "  # Messages have the type \"list\". The `add_messages` function\n",
        "    # in the annotation defines how this state key should be updated\n",
        "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
        "  messages:Annotated[list,add_messages]\n",
        "\n",
        "graph_builder=StateGraph(State)\n"
      ],
      "metadata": {
        "id": "dVzn-8rrC6-7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgjwX6BQDcfk",
        "outputId": "5d9229c3-9a6b-4fab-83e0-041089454327"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7ee0a4b31ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(state:State):#based on this State the state messages will be updated\n",
        "  return {\"messages\":llm.invoke(state['messages'])}"
      ],
      "metadata": {
        "id": "oOF74t5GDeJO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_node(\"chatbot\",chatbot)#in qoutes it is the name of the node"
      ],
      "metadata": {
        "id": "-m7NDe74EPGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e4bd2fc-ac77-4469-ba86-3580e11a852c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7ee0a4b31ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKFbmbqcEVIq",
        "outputId": "f4c947e6-bc50-47d8-c33a-ca8bb94cf3fd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7ee0a4b31ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_edge(START,\"chatbot\")# for adding the edges\n",
        "graph_builder.add_edge(\"chatbot\",END)"
      ],
      "metadata": {
        "id": "3jBWX44IEWy-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2e2e44b-b1bd-41cd-914c-a473843a61b0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7ee0a4b31ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph=graph_builder.compile()#entire graph is ready"
      ],
      "metadata": {
        "id": "PN4O63shEtyZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "try:\n",
        "  display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "  pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "_PPER3gfEygm",
        "outputId": "ad630649-91c3-44ae-8c39-3a0cea391c84"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  user_input=input(\"User: \")\n",
        "  if user_input.lower() in [\"quit\",\"q\"]:#breaking of the loop\n",
        "    print(\"Good Bye\")\n",
        "    break\n",
        "  for event in graph.stream({'messages':(\"user\",user_input)}):\n",
        "    print(event.values())\n",
        "    for value in event.values():\n",
        "      print(value['messages'])#user message\n",
        "      print(\"Assistant:\",value[\"messages\"].content)#Assitant message is basically the messages that are recieved from the llm's"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDvjUFmxFCwU",
        "outputId": "1c938870-5df0-4af5-ecf0-858b1890f447"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: helolo\n",
            "dict_values([{'messages': AIMessage(content='Hello! 👋  \\n\\nIt looks like you meant to say \"hello.\" How can I help you today? 😊 \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 11, 'total_tokens': 38, 'completion_time': 0.049090909, 'prompt_time': 0.0011773, 'queue_time': 0.092946694, 'total_time': 0.050268209}, 'model_name': 'gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--f775e43b-5c1f-4c4c-966d-ffc362849421-0', usage_metadata={'input_tokens': 11, 'output_tokens': 27, 'total_tokens': 38})}])\n",
            "content='Hello! 👋  \\n\\nIt looks like you meant to say \"hello.\" How can I help you today? 😊 \\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 11, 'total_tokens': 38, 'completion_time': 0.049090909, 'prompt_time': 0.0011773, 'queue_time': 0.092946694, 'total_time': 0.050268209}, 'model_name': 'gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--f775e43b-5c1f-4c4c-966d-ffc362849421-0' usage_metadata={'input_tokens': 11, 'output_tokens': 27, 'total_tokens': 38}\n",
            "Assistant: Hello! 👋  \n",
            "\n",
            "It looks like you meant to say \"hello.\" How can I help you today? 😊 \n",
            "\n",
            "User: What is Generative Ai ?\n",
            "dict_values([{'messages': AIMessage(content=\"Generative AI is a fascinating branch of artificial intelligence that focuses on creating new content rather than simply analyzing existing data. \\n\\nImagine AI that can write stories, compose music, paint pictures, or even generate code – that's generative AI in action!\\n\\nHere's a breakdown:\\n\\n**How it Works:**\\n\\nGenerative AI models are typically trained on massive datasets of text, images, audio, or other types of data. \\n\\n* They learn the underlying patterns and structures within this data.\\n\\n* Once trained, they can use this knowledge to generate new content that resembles the training data but is original and unique.\\n\\n**Key Techniques:**\\n\\n* **Generative Adversarial Networks (GANs):** Two AI models compete against each other. One generates content, and the other tries to distinguish it from real data. This adversarial process leads to increasingly realistic generated content.\\n* **Transformer Networks:**  Excellent at understanding and generating sequences of data, like text or code.\\n\\n**Examples of Generative AI:**\\n\\n* **Text Generation:** Chatbots like me, writing assistants, story generators, poem creators.\\n* **Image Generation:** Creating artwork, modifying existing images, generating photorealistic images from text descriptions (like DALL-E 2).\\n* **Music Generation:** Composing new melodies, creating entire songs in different styles.\\n* **Code Generation:**  Automating repetitive coding tasks, suggesting code snippets.\\n\\n**Potential Applications:**\\n\\n* **Creative Industries:**  Assisting writers, artists, musicians, and designers.\\n* **Marketing and Advertising:**  Generating personalized content, creating ad campaigns.\\n* **Education:**  Developing interactive learning experiences, providing personalized tutoring.\\n* **Research:**  Accelerating scientific discovery by generating hypotheses and exploring new ideas.\\n\\n**Ethical Considerations:**\\n\\n* **Bias:** Generative AI models can inherit and amplify biases present in the training data.\\n\\n* **Misinformation:**  The ability to generate realistic fake content raises concerns about the spread of misinformation.\\n* **Copyright:**  Questions surrounding the ownership and copyright of AI-generated content.\\n\\n\\nGenerative AI is a rapidly evolving field with immense potential to transform various aspects of our lives. It's important to approach its development and deployment responsibly, addressing the ethical challenges while harnessing its creative and innovative power.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 477, 'prompt_tokens': 15, 'total_tokens': 492, 'completion_time': 0.867272727, 'prompt_time': 0.001249709, 'queue_time': 0.069118563, 'total_time': 0.868522436}, 'model_name': 'gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--521666c0-4c82-4822-b902-4e55a7b58900-0', usage_metadata={'input_tokens': 15, 'output_tokens': 477, 'total_tokens': 492})}])\n",
            "content=\"Generative AI is a fascinating branch of artificial intelligence that focuses on creating new content rather than simply analyzing existing data. \\n\\nImagine AI that can write stories, compose music, paint pictures, or even generate code – that's generative AI in action!\\n\\nHere's a breakdown:\\n\\n**How it Works:**\\n\\nGenerative AI models are typically trained on massive datasets of text, images, audio, or other types of data. \\n\\n* They learn the underlying patterns and structures within this data.\\n\\n* Once trained, they can use this knowledge to generate new content that resembles the training data but is original and unique.\\n\\n**Key Techniques:**\\n\\n* **Generative Adversarial Networks (GANs):** Two AI models compete against each other. One generates content, and the other tries to distinguish it from real data. This adversarial process leads to increasingly realistic generated content.\\n* **Transformer Networks:**  Excellent at understanding and generating sequences of data, like text or code.\\n\\n**Examples of Generative AI:**\\n\\n* **Text Generation:** Chatbots like me, writing assistants, story generators, poem creators.\\n* **Image Generation:** Creating artwork, modifying existing images, generating photorealistic images from text descriptions (like DALL-E 2).\\n* **Music Generation:** Composing new melodies, creating entire songs in different styles.\\n* **Code Generation:**  Automating repetitive coding tasks, suggesting code snippets.\\n\\n**Potential Applications:**\\n\\n* **Creative Industries:**  Assisting writers, artists, musicians, and designers.\\n* **Marketing and Advertising:**  Generating personalized content, creating ad campaigns.\\n* **Education:**  Developing interactive learning experiences, providing personalized tutoring.\\n* **Research:**  Accelerating scientific discovery by generating hypotheses and exploring new ideas.\\n\\n**Ethical Considerations:**\\n\\n* **Bias:** Generative AI models can inherit and amplify biases present in the training data.\\n\\n* **Misinformation:**  The ability to generate realistic fake content raises concerns about the spread of misinformation.\\n* **Copyright:**  Questions surrounding the ownership and copyright of AI-generated content.\\n\\n\\nGenerative AI is a rapidly evolving field with immense potential to transform various aspects of our lives. It's important to approach its development and deployment responsibly, addressing the ethical challenges while harnessing its creative and innovative power.\\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 477, 'prompt_tokens': 15, 'total_tokens': 492, 'completion_time': 0.867272727, 'prompt_time': 0.001249709, 'queue_time': 0.069118563, 'total_time': 0.868522436}, 'model_name': 'gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--521666c0-4c82-4822-b902-4e55a7b58900-0' usage_metadata={'input_tokens': 15, 'output_tokens': 477, 'total_tokens': 492}\n",
            "Assistant: Generative AI is a fascinating branch of artificial intelligence that focuses on creating new content rather than simply analyzing existing data. \n",
            "\n",
            "Imagine AI that can write stories, compose music, paint pictures, or even generate code – that's generative AI in action!\n",
            "\n",
            "Here's a breakdown:\n",
            "\n",
            "**How it Works:**\n",
            "\n",
            "Generative AI models are typically trained on massive datasets of text, images, audio, or other types of data. \n",
            "\n",
            "* They learn the underlying patterns and structures within this data.\n",
            "\n",
            "* Once trained, they can use this knowledge to generate new content that resembles the training data but is original and unique.\n",
            "\n",
            "**Key Techniques:**\n",
            "\n",
            "* **Generative Adversarial Networks (GANs):** Two AI models compete against each other. One generates content, and the other tries to distinguish it from real data. This adversarial process leads to increasingly realistic generated content.\n",
            "* **Transformer Networks:**  Excellent at understanding and generating sequences of data, like text or code.\n",
            "\n",
            "**Examples of Generative AI:**\n",
            "\n",
            "* **Text Generation:** Chatbots like me, writing assistants, story generators, poem creators.\n",
            "* **Image Generation:** Creating artwork, modifying existing images, generating photorealistic images from text descriptions (like DALL-E 2).\n",
            "* **Music Generation:** Composing new melodies, creating entire songs in different styles.\n",
            "* **Code Generation:**  Automating repetitive coding tasks, suggesting code snippets.\n",
            "\n",
            "**Potential Applications:**\n",
            "\n",
            "* **Creative Industries:**  Assisting writers, artists, musicians, and designers.\n",
            "* **Marketing and Advertising:**  Generating personalized content, creating ad campaigns.\n",
            "* **Education:**  Developing interactive learning experiences, providing personalized tutoring.\n",
            "* **Research:**  Accelerating scientific discovery by generating hypotheses and exploring new ideas.\n",
            "\n",
            "**Ethical Considerations:**\n",
            "\n",
            "* **Bias:** Generative AI models can inherit and amplify biases present in the training data.\n",
            "\n",
            "* **Misinformation:**  The ability to generate realistic fake content raises concerns about the spread of misinformation.\n",
            "* **Copyright:**  Questions surrounding the ownership and copyright of AI-generated content.\n",
            "\n",
            "\n",
            "Generative AI is a rapidly evolving field with immense potential to transform various aspects of our lives. It's important to approach its development and deployment responsibly, addressing the ethical challenges while harnessing its creative and innovative power.\n",
            "\n",
            "User: Can you write me the code of Binary Search \n",
            "dict_values([{'messages': AIMessage(content='```python\\ndef binary_search(array, target):\\n  \"\"\"\\n  Performs a binary search on a sorted array.\\n\\n  Args:\\n      array: A sorted array of elements.\\n      target: The element to search for.\\n\\n  Returns:\\n      The index of the target element if found, otherwise -1.\\n  \"\"\"\\n\\n  left = 0\\n  right = len(array) - 1\\n\\n  while left <= right:\\n    mid = (left + right) // 2  # Calculate the middle index\\n\\n    if array[mid] == target:\\n      return mid  # Target found at the middle index\\n\\n    elif array[mid] < target:\\n      left = mid + 1  # Search the right half\\n\\n    else:\\n      right = mid - 1  # Search the left half\\n\\n  return -1  # Target not found in the array\\n\\n\\n# Example usage:\\nsorted_array = [2, 5, 7, 8, 11, 12]\\ntarget_element = 11\\n\\nindex = binary_search(sorted_array, target_element)\\n\\nif index != -1:\\n  print(f\"Target element {target_element} found at index {index}\")\\nelse:\\n  print(f\"Target element {target_element} not found in the array\")\\n```\\n\\n**Explanation:**\\n\\n1. **Initialization:**\\n   - `left`: Index of the leftmost element in the search range (initially 0).\\n   - `right`: Index of the rightmost element in the search range (initially the last index of the array).\\n\\n2. **Iteration:**\\n   - The `while` loop continues as long as `left` is less than or equal to `right`, meaning there\\'s still a valid search range.\\n   - **Calculate `mid`:** `mid = (left + right) // 2` finds the middle index of the current search range. We use floor division (`//`) to ensure `mid` is an integer.\\n\\n3. **Comparison:**\\n   - **`if array[mid] == target:`**: If the element at the middle index is equal to the target, we\\'ve found it! Return the `mid` index.\\n   - **`elif array[mid] < target:`**: If the middle element is less than the target, the target must be in the right half of the array. Update `left = mid + 1` to search the right portion.\\n   - **`else:`**: If the middle element is greater than the target, the target must be in the left half. Update `right = mid - 1` to search the left portion.\\n\\n4. **Target Not Found:**\\n   - If the loop completes without finding the target (i.e., `left` becomes greater than `right`), it means the target is not in the array. Return `-1` to indicate this.\\n\\n**Time Complexity:** O(log n) - Binary search is very efficient because it repeatedly halves the search space.\\n\\n\\n\\nLet me know if you have any other questions.\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 669, 'prompt_tokens': 19, 'total_tokens': 688, 'completion_time': 1.216363636, 'prompt_time': 0.00132756, 'queue_time': 0.091494346, 'total_time': 1.217691196}, 'model_name': 'gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--98108466-7396-4e48-abb0-949be2e9c070-0', usage_metadata={'input_tokens': 19, 'output_tokens': 669, 'total_tokens': 688})}])\n",
            "content='```python\\ndef binary_search(array, target):\\n  \"\"\"\\n  Performs a binary search on a sorted array.\\n\\n  Args:\\n      array: A sorted array of elements.\\n      target: The element to search for.\\n\\n  Returns:\\n      The index of the target element if found, otherwise -1.\\n  \"\"\"\\n\\n  left = 0\\n  right = len(array) - 1\\n\\n  while left <= right:\\n    mid = (left + right) // 2  # Calculate the middle index\\n\\n    if array[mid] == target:\\n      return mid  # Target found at the middle index\\n\\n    elif array[mid] < target:\\n      left = mid + 1  # Search the right half\\n\\n    else:\\n      right = mid - 1  # Search the left half\\n\\n  return -1  # Target not found in the array\\n\\n\\n# Example usage:\\nsorted_array = [2, 5, 7, 8, 11, 12]\\ntarget_element = 11\\n\\nindex = binary_search(sorted_array, target_element)\\n\\nif index != -1:\\n  print(f\"Target element {target_element} found at index {index}\")\\nelse:\\n  print(f\"Target element {target_element} not found in the array\")\\n```\\n\\n**Explanation:**\\n\\n1. **Initialization:**\\n   - `left`: Index of the leftmost element in the search range (initially 0).\\n   - `right`: Index of the rightmost element in the search range (initially the last index of the array).\\n\\n2. **Iteration:**\\n   - The `while` loop continues as long as `left` is less than or equal to `right`, meaning there\\'s still a valid search range.\\n   - **Calculate `mid`:** `mid = (left + right) // 2` finds the middle index of the current search range. We use floor division (`//`) to ensure `mid` is an integer.\\n\\n3. **Comparison:**\\n   - **`if array[mid] == target:`**: If the element at the middle index is equal to the target, we\\'ve found it! Return the `mid` index.\\n   - **`elif array[mid] < target:`**: If the middle element is less than the target, the target must be in the right half of the array. Update `left = mid + 1` to search the right portion.\\n   - **`else:`**: If the middle element is greater than the target, the target must be in the left half. Update `right = mid - 1` to search the left portion.\\n\\n4. **Target Not Found:**\\n   - If the loop completes without finding the target (i.e., `left` becomes greater than `right`), it means the target is not in the array. Return `-1` to indicate this.\\n\\n**Time Complexity:** O(log n) - Binary search is very efficient because it repeatedly halves the search space.\\n\\n\\n\\nLet me know if you have any other questions.\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 669, 'prompt_tokens': 19, 'total_tokens': 688, 'completion_time': 1.216363636, 'prompt_time': 0.00132756, 'queue_time': 0.091494346, 'total_time': 1.217691196}, 'model_name': 'gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--98108466-7396-4e48-abb0-949be2e9c070-0' usage_metadata={'input_tokens': 19, 'output_tokens': 669, 'total_tokens': 688}\n",
            "Assistant: ```python\n",
            "def binary_search(array, target):\n",
            "  \"\"\"\n",
            "  Performs a binary search on a sorted array.\n",
            "\n",
            "  Args:\n",
            "      array: A sorted array of elements.\n",
            "      target: The element to search for.\n",
            "\n",
            "  Returns:\n",
            "      The index of the target element if found, otherwise -1.\n",
            "  \"\"\"\n",
            "\n",
            "  left = 0\n",
            "  right = len(array) - 1\n",
            "\n",
            "  while left <= right:\n",
            "    mid = (left + right) // 2  # Calculate the middle index\n",
            "\n",
            "    if array[mid] == target:\n",
            "      return mid  # Target found at the middle index\n",
            "\n",
            "    elif array[mid] < target:\n",
            "      left = mid + 1  # Search the right half\n",
            "\n",
            "    else:\n",
            "      right = mid - 1  # Search the left half\n",
            "\n",
            "  return -1  # Target not found in the array\n",
            "\n",
            "\n",
            "# Example usage:\n",
            "sorted_array = [2, 5, 7, 8, 11, 12]\n",
            "target_element = 11\n",
            "\n",
            "index = binary_search(sorted_array, target_element)\n",
            "\n",
            "if index != -1:\n",
            "  print(f\"Target element {target_element} found at index {index}\")\n",
            "else:\n",
            "  print(f\"Target element {target_element} not found in the array\")\n",
            "```\n",
            "\n",
            "**Explanation:**\n",
            "\n",
            "1. **Initialization:**\n",
            "   - `left`: Index of the leftmost element in the search range (initially 0).\n",
            "   - `right`: Index of the rightmost element in the search range (initially the last index of the array).\n",
            "\n",
            "2. **Iteration:**\n",
            "   - The `while` loop continues as long as `left` is less than or equal to `right`, meaning there's still a valid search range.\n",
            "   - **Calculate `mid`:** `mid = (left + right) // 2` finds the middle index of the current search range. We use floor division (`//`) to ensure `mid` is an integer.\n",
            "\n",
            "3. **Comparison:**\n",
            "   - **`if array[mid] == target:`**: If the element at the middle index is equal to the target, we've found it! Return the `mid` index.\n",
            "   - **`elif array[mid] < target:`**: If the middle element is less than the target, the target must be in the right half of the array. Update `left = mid + 1` to search the right portion.\n",
            "   - **`else:`**: If the middle element is greater than the target, the target must be in the left half. Update `right = mid - 1` to search the left portion.\n",
            "\n",
            "4. **Target Not Found:**\n",
            "   - If the loop completes without finding the target (i.e., `left` becomes greater than `right`), it means the target is not in the array. Return `-1` to indicate this.\n",
            "\n",
            "**Time Complexity:** O(log n) - Binary search is very efficient because it repeatedly halves the search space.\n",
            "\n",
            "\n",
            "\n",
            "Let me know if you have any other questions.\n",
            "\n",
            "User: What is 0/0 ?\n",
            "dict_values([{'messages': AIMessage(content=\"0/0 is undefined. Here's why:\\n\\n* **Division as Sharing:** Think of division as sharing. If you have 0 cookies and want to share them equally among 0 friends, what does that mean?  It doesn't make sense!\\n\\n* **No Unique Answer:**  Division is about finding how many times one number goes into another. With 0/0, there's no single, unique answer that makes sense mathematically. You could argue for many different results.\\n\\n\\nLet me know if you have any other math questions! \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 118, 'prompt_tokens': 16, 'total_tokens': 134, 'completion_time': 0.214545455, 'prompt_time': 0.001247969, 'queue_time': 0.092537133, 'total_time': 0.215793424}, 'model_name': 'gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--3cb5ed76-7ee4-408b-8393-f7cf46395426-0', usage_metadata={'input_tokens': 16, 'output_tokens': 118, 'total_tokens': 134})}])\n",
            "content=\"0/0 is undefined. Here's why:\\n\\n* **Division as Sharing:** Think of division as sharing. If you have 0 cookies and want to share them equally among 0 friends, what does that mean?  It doesn't make sense!\\n\\n* **No Unique Answer:**  Division is about finding how many times one number goes into another. With 0/0, there's no single, unique answer that makes sense mathematically. You could argue for many different results.\\n\\n\\nLet me know if you have any other math questions! \\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 118, 'prompt_tokens': 16, 'total_tokens': 134, 'completion_time': 0.214545455, 'prompt_time': 0.001247969, 'queue_time': 0.092537133, 'total_time': 0.215793424}, 'model_name': 'gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--3cb5ed76-7ee4-408b-8393-f7cf46395426-0' usage_metadata={'input_tokens': 16, 'output_tokens': 118, 'total_tokens': 134}\n",
            "Assistant: 0/0 is undefined. Here's why:\n",
            "\n",
            "* **Division as Sharing:** Think of division as sharing. If you have 0 cookies and want to share them equally among 0 friends, what does that mean?  It doesn't make sense!\n",
            "\n",
            "* **No Unique Answer:**  Division is about finding how many times one number goes into another. With 0/0, there's no single, unique answer that makes sense mathematically. You could argue for many different results.\n",
            "\n",
            "\n",
            "Let me know if you have any other math questions! \n",
            "\n",
            "User: what is 120/10?\n",
            "dict_values([{'messages': AIMessage(content='120/10 = 12 \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 19, 'total_tokens': 33, 'completion_time': 0.025454545, 'prompt_time': 0.001327989, 'queue_time': 0.070054304, 'total_time': 0.026782534}, 'model_name': 'gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--59e8f635-1821-48a9-aa78-fb493716ef07-0', usage_metadata={'input_tokens': 19, 'output_tokens': 14, 'total_tokens': 33})}])\n",
            "content='120/10 = 12 \\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 19, 'total_tokens': 33, 'completion_time': 0.025454545, 'prompt_time': 0.001327989, 'queue_time': 0.070054304, 'total_time': 0.026782534}, 'model_name': 'gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--59e8f635-1821-48a9-aa78-fb493716ef07-0' usage_metadata={'input_tokens': 19, 'output_tokens': 14, 'total_tokens': 33}\n",
            "Assistant: 120/10 = 12 \n",
            "\n",
            "User: q\n",
            "Good Bye\n"
          ]
        }
      ]
    }
  ]
}